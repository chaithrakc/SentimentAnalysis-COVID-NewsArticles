{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","mount_file_id":"1uK9-XOFVE_boIWxM28xGewQFlN2X0MdK","authorship_tag":"ABX9TyNP9KzBuUSKfjFLIGJe4hEF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"a5b6fce38d174238a888ee73d7b331ed":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_013ec07469ee460aa00ef56e8e1a6ab0","IPY_MODEL_bc0e6e5eb7104052b473d69f6fcb6f69","IPY_MODEL_b5ab49a295824308be49fda6af162701"],"layout":"IPY_MODEL_2ad92085588a4cd6ac00d1d80b33dede"}},"013ec07469ee460aa00ef56e8e1a6ab0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_78ead454defd4994aa34c264c54107bf","placeholder":"​","style":"IPY_MODEL_70324e65b1ea451cb9acbe619ae845a7","value":"Downloading: 100%"}},"bc0e6e5eb7104052b473d69f6fcb6f69":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2bc5e4f8d5d4366b011a443bc5d2dcd","max":798011,"min":0,"orientation":"horizontal","style":"IPY_MODEL_977c1cb3e5b84e96963a0c0bd4231cf9","value":798011}},"b5ab49a295824308be49fda6af162701":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_89840a3a4e8840f59289d0ea2fd7ce02","placeholder":"​","style":"IPY_MODEL_176896f12d7a430090b3d39578c70a12","value":" 779k/779k [00:00&lt;00:00, 642kB/s]"}},"2ad92085588a4cd6ac00d1d80b33dede":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78ead454defd4994aa34c264c54107bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70324e65b1ea451cb9acbe619ae845a7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d2bc5e4f8d5d4366b011a443bc5d2dcd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"977c1cb3e5b84e96963a0c0bd4231cf9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"89840a3a4e8840f59289d0ea2fd7ce02":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"176896f12d7a430090b3d39578c70a12":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"845b8f9f727643f9b899db652435a6b9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_90e9707a93494a3abde9a32345e1a282","IPY_MODEL_de1c0e60a7af475c833f8e5ce89243cb","IPY_MODEL_88f8608aa607498ba289b2be734bb01e"],"layout":"IPY_MODEL_3b59db5b66e84842821ba46025afd9aa"}},"90e9707a93494a3abde9a32345e1a282":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7dd3491a371c4e2a856f05558677118d","placeholder":"​","style":"IPY_MODEL_ad77f1dffc164a2491900b04cf63c475","value":"Downloading: 100%"}},"de1c0e60a7af475c833f8e5ce89243cb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cbfda8055c524aec97a3572777aacf24","max":760,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ace4e8e516ca42e880e421308c666a4e","value":760}},"88f8608aa607498ba289b2be734bb01e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_568b19fefb0146bcb4807d5903343eba","placeholder":"​","style":"IPY_MODEL_b84d7a900d3741b396cb12e34682b395","value":" 760/760 [00:00&lt;00:00, 26.0kB/s]"}},"3b59db5b66e84842821ba46025afd9aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7dd3491a371c4e2a856f05558677118d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad77f1dffc164a2491900b04cf63c475":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cbfda8055c524aec97a3572777aacf24":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ace4e8e516ca42e880e421308c666a4e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"568b19fefb0146bcb4807d5903343eba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b84d7a900d3741b396cb12e34682b395":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"43af434d7798437b9e830f2688fa4c99":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_081c2a88ef8046da8cf6abafb394bc7d","IPY_MODEL_0872307fc9b74e29aef7afab0a979b6a","IPY_MODEL_eb15f49c18fc4250a4815f4f59725256"],"layout":"IPY_MODEL_c1b1515f250843798179c34bd9c92b10"}},"081c2a88ef8046da8cf6abafb394bc7d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7041b857816e48c392f9e622da835c7b","placeholder":"​","style":"IPY_MODEL_5efc441a47ec4ff19d532d9a65f57ece","value":"Downloading: 100%"}},"0872307fc9b74e29aef7afab0a979b6a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_212f8373ff7248ff921adb6a037e2c7f","max":565485600,"min":0,"orientation":"horizontal","style":"IPY_MODEL_65e5cfe6b0c04764b12f7da124f12f92","value":565485600}},"eb15f49c18fc4250a4815f4f59725256":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8178ac4036c0479587f2cf5b67ac7c65","placeholder":"​","style":"IPY_MODEL_ca6cd50eb6f648878de592137596bb5d","value":" 539M/539M [00:30&lt;00:00, 12.1MB/s]"}},"c1b1515f250843798179c34bd9c92b10":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7041b857816e48c392f9e622da835c7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5efc441a47ec4ff19d532d9a65f57ece":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"212f8373ff7248ff921adb6a037e2c7f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65e5cfe6b0c04764b12f7da124f12f92":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8178ac4036c0479587f2cf5b67ac7c65":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ca6cd50eb6f648878de592137596bb5d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"20399eceaaf1413ebad57b75fbe61716":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f68c7090f95b48f082b229c55fd02564","IPY_MODEL_2fc706c69e9646c2958c51abd13f0bec","IPY_MODEL_c5ea4846e71f4be38218e36f625f1f50"],"layout":"IPY_MODEL_71d573db06ec4a5fa39a6cdd9a2c889a"}},"f68c7090f95b48f082b229c55fd02564":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1aa52221f20c4e7e885cfb886a8654ec","placeholder":"​","style":"IPY_MODEL_97f32e1aae624951831508301f52a851","value":"Downloading: 100%"}},"2fc706c69e9646c2958c51abd13f0bec":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ece4ca554e424be1a4293d4fbc18169c","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_88f8afb7da7747bd82630de3b2a6e60e","value":231508}},"c5ea4846e71f4be38218e36f625f1f50":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1828174fc1f64ed8ac887581eee2e4a9","placeholder":"​","style":"IPY_MODEL_0231d516393b4e52bb950e48c255d54a","value":" 226k/226k [00:00&lt;00:00, 2.39MB/s]"}},"71d573db06ec4a5fa39a6cdd9a2c889a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1aa52221f20c4e7e885cfb886a8654ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97f32e1aae624951831508301f52a851":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ece4ca554e424be1a4293d4fbc18169c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88f8afb7da7747bd82630de3b2a6e60e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1828174fc1f64ed8ac887581eee2e4a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0231d516393b4e52bb950e48c255d54a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ed91e64f719f43c0bc222a755b63b90f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b39c5fae42d749efada08fb1c4134853","IPY_MODEL_bb260b9338d44dd787f6c989fd222105","IPY_MODEL_83feaa5a748f46ce94e0ef3fb3c60f91"],"layout":"IPY_MODEL_11f3d61d1d89452a993c279bc93e9626"}},"b39c5fae42d749efada08fb1c4134853":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc4444791bae4cebab4d33d4851643aa","placeholder":"​","style":"IPY_MODEL_1d6164949a0c4674b3c3f405223f0c6d","value":"Downloading: 100%"}},"bb260b9338d44dd787f6c989fd222105":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_444f1d02a8604bd2bcc6b28971d6be45","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ffd5e8b23a454c8e8a360a329057b917","value":28}},"83feaa5a748f46ce94e0ef3fb3c60f91":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed072667fa004443ac180e1d74bbe2ec","placeholder":"​","style":"IPY_MODEL_193fa27152de44c8b4e7a3af4255d896","value":" 28.0/28.0 [00:00&lt;00:00, 783B/s]"}},"11f3d61d1d89452a993c279bc93e9626":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc4444791bae4cebab4d33d4851643aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d6164949a0c4674b3c3f405223f0c6d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"444f1d02a8604bd2bcc6b28971d6be45":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ffd5e8b23a454c8e8a360a329057b917":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ed072667fa004443ac180e1d74bbe2ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"193fa27152de44c8b4e7a3af4255d896":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7d7afcf5538341aea71918ac18a047b9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8fc48420d2544ca59a88d566e61a21eb","IPY_MODEL_342070d5bab849d69227362e945c8995","IPY_MODEL_55f218dbf66d4be7a9fcbad8cc9a27ae"],"layout":"IPY_MODEL_0ea80dbd12d54315a9ef6db6713ff12a"}},"8fc48420d2544ca59a88d566e61a21eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f9de4ba695664882abfc913277e56c9b","placeholder":"​","style":"IPY_MODEL_250ca7c9295f4ab38fd0f1e75a2779f0","value":"Downloading: 100%"}},"342070d5bab849d69227362e945c8995":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b0097b700ea497498f18705680520ae","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_254aba906b2242608698114322ff62c6","value":570}},"55f218dbf66d4be7a9fcbad8cc9a27ae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dee35c6ed8c3450096f4a94254e0c8bd","placeholder":"​","style":"IPY_MODEL_f1c9d73b42014772a08fc695af6f62bb","value":" 570/570 [00:00&lt;00:00, 21.6kB/s]"}},"0ea80dbd12d54315a9ef6db6713ff12a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9de4ba695664882abfc913277e56c9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"250ca7c9295f4ab38fd0f1e75a2779f0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5b0097b700ea497498f18705680520ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"254aba906b2242608698114322ff62c6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dee35c6ed8c3450096f4a94254e0c8bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1c9d73b42014772a08fc695af6f62bb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1545e3baccad4a918234dfbcecc08a80":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c89ef94166e54a69ba5fff45fc4a4c27","IPY_MODEL_a1806e3d23e5405bb31a2274db2c58bb","IPY_MODEL_0e42e3889e0f4de5ae24d53502ef4536"],"layout":"IPY_MODEL_075f493254ed4d038e99180fdb8aab1e"}},"c89ef94166e54a69ba5fff45fc4a4c27":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_adf59bfd86c045cbbea7008a05d58f8b","placeholder":"​","style":"IPY_MODEL_c951a50a91804c8c906d3ab9d93aba77","value":"Downloading: 100%"}},"a1806e3d23e5405bb31a2274db2c58bb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d1c0a0a617f4508be9419a9bc0f8d3d","max":536063208,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e2f33fcb2a2c4519b057392a4db443cb","value":536063208}},"0e42e3889e0f4de5ae24d53502ef4536":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e5ca558818244dba7a23d18f4dd532d","placeholder":"​","style":"IPY_MODEL_7c31a839fbfd4ed7999d1545ca5ea599","value":" 511M/511M [00:11&lt;00:00, 43.6MB/s]"}},"075f493254ed4d038e99180fdb8aab1e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"adf59bfd86c045cbbea7008a05d58f8b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c951a50a91804c8c906d3ab9d93aba77":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1d1c0a0a617f4508be9419a9bc0f8d3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2f33fcb2a2c4519b057392a4db443cb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3e5ca558818244dba7a23d18f4dd532d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c31a839fbfd4ed7999d1545ca5ea599":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["1. Loading the Data\n","2. Data Pre-Processing\n","    - Data Cleaning\n","        - Lowercase Transformation\n","        - Removing Special Characters and Numeric Values\n","    - Encoding Sentiment Variable\n","    - Stop Word Removal\n","    - Lemmatization\n","3. Model having BERT Word Embedding + StopWords\n","4. Model having XLNet Word Embedding + StopWords\n","5. Model having BERT Word Embedding + No StopWords\n","6. Model having XLNet Word Embedding + No StopWords\n","7. Model having XLNet Word Embedding + Lemmatization + Stop Words\n","10. Predicting Sentiments"],"metadata":{"id":"DBRNi_0b5oKh"}},{"cell_type":"code","source":["!pip install allennlp"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FI4nuTriXG89","executionInfo":{"status":"ok","timestamp":1651471967288,"user_tz":240,"elapsed":91843,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"332e9cfc-4f4e-4969-e315-4c51795afd52"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting allennlp\n","  Downloading allennlp-2.9.3-py3-none-any.whl (719 kB)\n","\u001b[K     |████████████████████████████████| 719 kB 5.4 MB/s \n","\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from allennlp) (0.3.4)\n","Collecting jsonnet>=0.10.0\n","  Downloading jsonnet-0.18.0.tar.gz (592 kB)\n","\u001b[K     |████████████████████████████████| 592 kB 52.4 MB/s \n","\u001b[?25hRequirement already satisfied: torch<1.12.0,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from allennlp) (1.11.0+cu113)\n","Collecting tensorboardX>=1.2\n","  Downloading tensorboardX-2.5-py2.py3-none-any.whl (125 kB)\n","\u001b[K     |████████████████████████████████| 125 kB 53.4 MB/s \n","\u001b[?25hCollecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 39.7 MB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from allennlp) (1.4.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from allennlp) (1.21.6)\n","Requirement already satisfied: torchvision<0.13.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from allennlp) (0.12.0+cu113)\n","Collecting base58\n","  Downloading base58-2.1.1-py3-none-any.whl (5.6 kB)\n","Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.7/dist-packages (from allennlp) (2.23.0)\n","Requirement already satisfied: filelock<3.7,>=3.3 in /usr/local/lib/python3.7/dist-packages (from allennlp) (3.6.0)\n","Requirement already satisfied: spacy<3.3,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from allennlp) (2.2.4)\n","Collecting huggingface-hub>=0.0.16\n","  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n","\u001b[K     |████████████████████████████████| 77 kB 5.1 MB/s \n","\u001b[?25hCollecting typer>=0.4.1\n","  Downloading typer-0.4.1-py3-none-any.whl (27 kB)\n","Collecting cached-path<1.2.0,>=1.0.2\n","  Downloading cached_path-1.1.2-py3-none-any.whl (26 kB)\n","Requirement already satisfied: tqdm>=4.62 in /usr/local/lib/python3.7/dist-packages (from allennlp) (4.64.0)\n","Collecting transformers<4.19,>=4.1\n","  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n","\u001b[K     |████████████████████████████████| 4.0 MB 33.8 MB/s \n","\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from allennlp) (3.6.4)\n","Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from allennlp) (8.12.0)\n","Collecting wandb<0.13.0,>=0.10.0\n","  Downloading wandb-0.12.15-py2.py3-none-any.whl (1.8 MB)\n","\u001b[K     |████████████████████████████████| 1.8 MB 36.6 MB/s \n","\u001b[?25hCollecting fairscale==0.4.6\n","  Downloading fairscale-0.4.6.tar.gz (248 kB)\n","\u001b[K     |████████████████████████████████| 248 kB 66.3 MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from allennlp) (3.2.5)\n","Requirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.7/dist-packages (from allennlp) (1.1.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from allennlp) (3.1.0)\n","Requirement already satisfied: lmdb in /usr/local/lib/python3.7/dist-packages (from allennlp) (0.99)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from allennlp) (1.0.2)\n","Requirement already satisfied: google-cloud-storage<3.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from cached-path<1.2.0,>=1.0.2->allennlp) (1.18.1)\n","Collecting boto3<2.0,>=1.0\n","  Downloading boto3-1.22.4-py3-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 60.2 MB/s \n","\u001b[?25hCollecting s3transfer<0.6.0,>=0.5.0\n","  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 7.7 MB/s \n","\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n","  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n","Collecting botocore<1.26.0,>=1.25.4\n","  Downloading botocore-1.25.4-py3-none-any.whl (8.7 MB)\n","\u001b[K     |████████████████████████████████| 8.7 MB 48.5 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.26.0,>=1.25.4->boto3<2.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp) (2.8.2)\n","Collecting urllib3<1.27,>=1.25.4\n","  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n","\u001b[K     |████████████████████████████████| 138 kB 64.5 MB/s \n","\u001b[?25hRequirement already satisfied: google-resumable-media<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage<3.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp) (0.4.1)\n","Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage<3.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp) (1.0.3)\n","Requirement already satisfied: google-auth>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage<3.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp) (1.35.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2.0->google-cloud-storage<3.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2.0->google-cloud-storage<3.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp) (0.2.8)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2.0->google-cloud-storage<3.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp) (1.15.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2.0->google-cloud-storage<3.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp) (4.8)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2.0->google-cloud-storage<3.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp) (57.4.0)\n","Requirement already satisfied: google-api-core<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage<3.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp) (1.31.5)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage<3.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp) (2022.1)\n","Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage<3.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp) (21.3)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage<3.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp) (3.17.3)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage<3.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp) (1.56.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.16->allennlp) (4.11.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.16->allennlp) (4.2.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.16->allennlp) (3.13)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage<3.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp) (3.0.8)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2.0->google-cloud-storage<3.0,>=1.0->cached-path<1.2.0,>=1.0.2->allennlp) (0.4.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp) (2021.10.8)\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 64.9 MB/s \n","\u001b[?25hRequirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3,>=2.1.0->allennlp) (1.1.3)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3,>=2.1.0->allennlp) (1.0.5)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3,>=2.1.0->allennlp) (0.4.1)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3,>=2.1.0->allennlp) (2.0.6)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3,>=2.1.0->allennlp) (0.9.1)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3,>=2.1.0->allennlp) (1.0.0)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3,>=2.1.0->allennlp) (1.0.7)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3,>=2.1.0->allennlp) (7.4.0)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3,>=2.1.0->allennlp) (3.0.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub>=0.0.16->allennlp) (3.8.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision<0.13.0,>=0.8.1->allennlp) (7.1.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<4.19,>=4.1->allennlp) (2019.12.20)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 51.1 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 36.6 MB/s \n","\u001b[?25hCollecting pyyaml\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 55.3 MB/s \n","\u001b[?25hRequirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer>=0.4.1->allennlp) (7.1.2)\n","Collecting docker-pycreds>=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting setproctitle\n","  Downloading setproctitle-1.2.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n","Collecting shortuuid>=0.5.0\n","  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (5.4.8)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.5.10-py2.py3-none-any.whl (144 kB)\n","\u001b[K     |████████████████████████████████| 144 kB 62.4 MB/s \n","\u001b[?25hCollecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (2.3)\n","Collecting GitPython>=1.0.0\n","  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n","\u001b[K     |████████████████████████████████| 181 kB 50.0 MB/s \n","\u001b[?25hCollecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n","\u001b[?25hCollecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->allennlp) (1.5.2)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp) (21.4.0)\n","Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp) (1.4.0)\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp) (1.11.0)\n","Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp) (0.7.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<4.19,>=4.1->allennlp) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->allennlp) (3.1.0)\n","Building wheels for collected packages: fairscale, jsonnet, pathtools\n","  Building wheel for fairscale (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fairscale: filename=fairscale-0.4.6-py3-none-any.whl size=307252 sha256=0cf1a4706466a34f871dd83b89b7426b18693842cd7e0d4c1981615f8152f2fd\n","  Stored in directory: /root/.cache/pip/wheels/4e/4f/0b/94c29ea06dfad93260cb0377855f87b7b863312317a7f69fe7\n","  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for jsonnet: filename=jsonnet-0.18.0-cp37-cp37m-linux_x86_64.whl size=3994711 sha256=3870dacb9ba0028560f59fba314e11b3282a3ded2d85d23ab1894e2591c307bc\n","  Stored in directory: /root/.cache/pip/wheels/a9/63/f9/a653f9c21575e6ff271ee6a49939aa002005174cea6c35919d\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=a0a91d7f49735256dc083906a32a9e42e4127365183c58f9d11760edf65eeed6\n","  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n","Successfully built fairscale jsonnet pathtools\n","Installing collected packages: urllib3, jmespath, smmap, botocore, s3transfer, pyyaml, gitdb, tokenizers, shortuuid, setproctitle, sentry-sdk, sacremoses, pathtools, huggingface-hub, GitPython, docker-pycreds, boto3, wandb, typer, transformers, tensorboardX, sentencepiece, jsonnet, fairscale, cached-path, base58, allennlp\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed GitPython-3.1.27 allennlp-2.9.3 base58-2.1.1 boto3-1.22.4 botocore-1.25.4 cached-path-1.1.2 docker-pycreds-0.4.0 fairscale-0.4.6 gitdb-4.0.9 huggingface-hub-0.5.1 jmespath-1.0.0 jsonnet-0.18.0 pathtools-0.1.2 pyyaml-6.0 s3transfer-0.5.2 sacremoses-0.0.49 sentencepiece-0.1.96 sentry-sdk-1.5.10 setproctitle-1.2.3 shortuuid-1.0.8 smmap-5.0.0 tensorboardX-2.5 tokenizers-0.12.1 transformers-4.18.0 typer-0.4.1 urllib3-1.25.11 wandb-0.12.15\n"]}]},{"cell_type":"code","source":["# importing required libraries\n","import pandas as pd\n","import json\n","import seaborn as sns\n","import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords # We will do some cleanup of the text\n","import matplotlib.pyplot as plt\n","import re\n","import numpy as np\n","from tqdm import tqdm\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from transformers import BertTokenizer, TFBertModel,XLNetModel, XLNetTokenizer,TFXLNetModel\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","from keras.layers import CuDNNLSTM\n","from tensorflow.keras.layers import Embedding,LSTM, Dense, Bidirectional\n","from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n","from sklearn.model_selection import train_test_split"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3rKtm-9kAdTe","executionInfo":{"status":"ok","timestamp":1651471976173,"user_tz":240,"elapsed":8896,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"dc74b636-f889-4f56-c5ca-7e17bf308027"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}]},{"cell_type":"markdown","source":["# 1. Loading the Data"],"metadata":{"id":"T5WNvBFf_-_j"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d7qtOjTA3Tr4","executionInfo":{"status":"ok","timestamp":1651471987452,"user_tz":240,"elapsed":11285,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"5dfacab7-8a10-494e-bc34-824eb838c09c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"output_type":"execute_result","data":{"text/plain":["(14640, 15)"]},"metadata":{},"execution_count":4}],"source":["# using twitter dataset from kaggle https://www.kaggle.com/crowdflower/twitter-airline-sentiment for training the model\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","tweetsdf = pd.read_csv('/content/drive/Othercomputers/My Laptop/syr_ads_ist664/hw03/Tweets.zip')\n","tweetsdf.shape"]},{"cell_type":"code","source":["tweetsdf.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":496},"id":"LEO3pDqGAYEB","executionInfo":{"status":"ok","timestamp":1651471987454,"user_tz":240,"elapsed":33,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"795f78c2-d7b9-47a1-db2a-2934f287b670"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n","0  570306133677760513           neutral                        1.0000   \n","1  570301130888122368          positive                        0.3486   \n","2  570301083672813571           neutral                        0.6837   \n","3  570301031407624196          negative                        1.0000   \n","4  570300817074462722          negative                        1.0000   \n","\n","  negativereason  negativereason_confidence         airline  \\\n","0            NaN                        NaN  Virgin America   \n","1            NaN                     0.0000  Virgin America   \n","2            NaN                        NaN  Virgin America   \n","3     Bad Flight                     0.7033  Virgin America   \n","4     Can't Tell                     1.0000  Virgin America   \n","\n","  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n","0                    NaN     cairdin                 NaN              0   \n","1                    NaN    jnardino                 NaN              0   \n","2                    NaN  yvonnalynn                 NaN              0   \n","3                    NaN    jnardino                 NaN              0   \n","4                    NaN    jnardino                 NaN              0   \n","\n","                                                text tweet_coord  \\\n","0                @VirginAmerica What @dhepburn said.         NaN   \n","1  @VirginAmerica plus you've added commercials t...         NaN   \n","2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n","3  @VirginAmerica it's really aggressive to blast...         NaN   \n","4  @VirginAmerica and it's a really big bad thing...         NaN   \n","\n","               tweet_created tweet_location               user_timezone  \n","0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n","1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n","2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n","3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n","4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "],"text/html":["\n","  <div id=\"df-5cf49f45-8549-4c1f-a057-3590c4d0a71d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tweet_id</th>\n","      <th>airline_sentiment</th>\n","      <th>airline_sentiment_confidence</th>\n","      <th>negativereason</th>\n","      <th>negativereason_confidence</th>\n","      <th>airline</th>\n","      <th>airline_sentiment_gold</th>\n","      <th>name</th>\n","      <th>negativereason_gold</th>\n","      <th>retweet_count</th>\n","      <th>text</th>\n","      <th>tweet_coord</th>\n","      <th>tweet_created</th>\n","      <th>tweet_location</th>\n","      <th>user_timezone</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>570306133677760513</td>\n","      <td>neutral</td>\n","      <td>1.0000</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Virgin America</td>\n","      <td>NaN</td>\n","      <td>cairdin</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>@VirginAmerica What @dhepburn said.</td>\n","      <td>NaN</td>\n","      <td>2015-02-24 11:35:52 -0800</td>\n","      <td>NaN</td>\n","      <td>Eastern Time (US &amp; Canada)</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>570301130888122368</td>\n","      <td>positive</td>\n","      <td>0.3486</td>\n","      <td>NaN</td>\n","      <td>0.0000</td>\n","      <td>Virgin America</td>\n","      <td>NaN</td>\n","      <td>jnardino</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>@VirginAmerica plus you've added commercials t...</td>\n","      <td>NaN</td>\n","      <td>2015-02-24 11:15:59 -0800</td>\n","      <td>NaN</td>\n","      <td>Pacific Time (US &amp; Canada)</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>570301083672813571</td>\n","      <td>neutral</td>\n","      <td>0.6837</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Virgin America</td>\n","      <td>NaN</td>\n","      <td>yvonnalynn</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n","      <td>NaN</td>\n","      <td>2015-02-24 11:15:48 -0800</td>\n","      <td>Lets Play</td>\n","      <td>Central Time (US &amp; Canada)</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>570301031407624196</td>\n","      <td>negative</td>\n","      <td>1.0000</td>\n","      <td>Bad Flight</td>\n","      <td>0.7033</td>\n","      <td>Virgin America</td>\n","      <td>NaN</td>\n","      <td>jnardino</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>@VirginAmerica it's really aggressive to blast...</td>\n","      <td>NaN</td>\n","      <td>2015-02-24 11:15:36 -0800</td>\n","      <td>NaN</td>\n","      <td>Pacific Time (US &amp; Canada)</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>570300817074462722</td>\n","      <td>negative</td>\n","      <td>1.0000</td>\n","      <td>Can't Tell</td>\n","      <td>1.0000</td>\n","      <td>Virgin America</td>\n","      <td>NaN</td>\n","      <td>jnardino</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>@VirginAmerica and it's a really big bad thing...</td>\n","      <td>NaN</td>\n","      <td>2015-02-24 11:14:45 -0800</td>\n","      <td>NaN</td>\n","      <td>Pacific Time (US &amp; Canada)</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5cf49f45-8549-4c1f-a057-3590c4d0a71d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5cf49f45-8549-4c1f-a057-3590c4d0a71d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5cf49f45-8549-4c1f-a057-3590c4d0a71d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["# 2. Data Pre-Processing"],"metadata":{"id":"YlPoCPQICDYb"}},{"cell_type":"markdown","source":["**Data Cleaning**"],"metadata":{"id":"-_FfIiQJCHBu"}},{"cell_type":"code","source":["def returnCleanText(text):\n","        text = text.lower() # lowercase transformation\n","        text = re.sub(r'(@\\w+.*?)','',text) # removing twitter name tags\n","        text = re.sub(r'(#\\w+.*?)','',text) # removing twitter hash tags\n","        text = re.sub(r\"\\W+|_\", ' ', text) # removing numbers, punctuations, and underscore in the text retaining only alphatecial words\n","        return text\n","\n","# Now use the apply() method to run the function on each text    \n","tweetsdf['clean_text'] = tweetsdf['text'].apply(returnCleanText)"],"metadata":{"id":"hzumbzLYD23E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tweetsdf['clean_text']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pwjz8WhBBc-9","executionInfo":{"status":"ok","timestamp":1651471987908,"user_tz":240,"elapsed":21,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"7eeddd64-4253-4dbb-f50c-b64dc7ebe9d5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0                                               what said \n","1         plus you ve added commercials to the experien...\n","2         i didn t today must mean i need to take anoth...\n","3         it s really aggressive to blast obnoxious ent...\n","4                 and it s a really big bad thing about it\n","                               ...                        \n","14635     thank you we got on a different flight to chi...\n","14636     leaving over 20 minutes late flight no warnin...\n","14637                   please bring american airlines to \n","14638     you have my money you change my flight and do...\n","14639     we have 8 ppl so we need 2 know how many seat...\n","Name: clean_text, Length: 14640, dtype: object"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["**Encoding Sentiment Variable**"],"metadata":{"id":"s3zEI-EPJmBo"}},{"cell_type":"code","source":["# Unique values of sentiment\n","tweetsdf['airline_sentiment'].unique()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"txKFAcL2BjkZ","executionInfo":{"status":"ok","timestamp":1651471987910,"user_tz":240,"elapsed":18,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"75e3f056-c489-4025-f766-d78c552689f5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['neutral', 'positive', 'negative'], dtype=object)"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["# Unique values of sentiment plot\n","ax = sns.countplot(x=\"airline_sentiment\", data=tweetsdf)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":280},"id":"xdbmwQjlBlcW","executionInfo":{"status":"ok","timestamp":1651471988089,"user_tz":240,"elapsed":188,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"1a2656e1-a084-4709-8217-6870c072920f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["tweetsdf['airline_sentiment'].replace({'neutral':0, 'negative':1, 'positive':2}, inplace=True)"],"metadata":{"id":"twM9rbcxHz1J"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Positive and neutral tweets are almost equal. Negative tweets are more than double of neutral or positive sentiments."],"metadata":{"id":"R_IlXuFgCSni"}},{"cell_type":"code","source":["df = tweetsdf[[\"clean_text\",\"airline_sentiment\"]]\n","df.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GSR0LxHEJGdn","executionInfo":{"status":"ok","timestamp":1651471988092,"user_tz":240,"elapsed":19,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"1cb0fa59-9a52-4b09-eb0b-0b445f43c891"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(14640, 2)"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["**Stop Word Removal**"],"metadata":{"id":"d1ElDcD1Jpiu"}},{"cell_type":"code","source":["my_stops = stopwords.words('english') #loading all the stop words in english language provided by nltk package\n","stop_pat = r'\\b(?:{})\\b'.format('|'.join(my_stops)) # combining all the stop words by a delimiter '|' so that we can find\n","def removeStopWords(text):\n","  return re.sub(stop_pat, '', text) # remvoing all the stop words "],"metadata":{"id":"4JsdIE4_KYPa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['nostop_words'] = df['clean_text'].apply(removeStopWords)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MAmr6bPFJO8R","executionInfo":{"status":"ok","timestamp":1651471988510,"user_tz":240,"elapsed":431,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"aaf14fee-eb0a-432a-e514-80d138f381c2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \"\"\"Entry point for launching an IPython kernel.\n"]}]},{"cell_type":"code","source":["df['nostop_words']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jV8rth9sK5uT","executionInfo":{"status":"ok","timestamp":1651471988511,"user_tz":240,"elapsed":14,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"00fa9819-63a0-4635-d857-9fa95c8fc0b8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0                                                    said \n","1             plus   added commercials   experience tacky \n","2                today must mean  need  take another trip \n","3           really aggressive  blast obnoxious entertai...\n","4                                   really big bad thing  \n","                               ...                        \n","14635             thank   got   different flight  chicago \n","14636     leaving  20 minutes late flight  warnings  co...\n","14637                     please bring american airlines  \n","14638        money  change  flight    answer  phones   ...\n","14639       8 ppl   need 2 know  many seats    next fli...\n","Name: nostop_words, Length: 14640, dtype: object"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["**Lemmatization**"],"metadata":{"id":"rbuH4HsEJqcj"}},{"cell_type":"code","source":["import spacy\n","nlp = spacy.load('en_core_web_sm')"],"metadata":{"id":"0lQodHTWXRRD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# time consuming. takes around 1-2 mins to lemmatize entire corpus\n","def lemmatizing_tweets(text):\n","  doc = nlp(text)\n","  return \" \".join([token.lemma_ for token in doc])\n","\n","df['lemmatized_text'] = df['clean_text'].apply(lemmatizing_tweets)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0St_YTGvXq2T","executionInfo":{"status":"ok","timestamp":1651472131831,"user_tz":240,"elapsed":140258,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"eff06b89-ab3c-40af-b79b-3780b3398668"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \n"]}]},{"cell_type":"code","source":["df['lemmatized_text'] "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0_EIZ9KPYpUl","executionInfo":{"status":"ok","timestamp":1651472131832,"user_tz":240,"elapsed":22,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"242594b2-8f4d-48c6-ddc2-215c14016338"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0                                                 what say\n","1          plus -PRON- ve add commercial to the experie...\n","2          i didn t today must mean i need to take anot...\n","3          -PRON- s really aggressive to blast obnoxiou...\n","4          and -PRON- s a really big bad thing about -P...\n","                               ...                        \n","14635      thank -PRON- -PRON- get on a different fligh...\n","14636      leave over 20 minute late flight no warning ...\n","14637                     please bring american airline to\n","14638      -PRON- have -PRON- money -PRON- change -PRON...\n","14639      -PRON- have 8 ppl so -PRON- need 2 know how ...\n","Name: lemmatized_text, Length: 14640, dtype: object"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["# time consuming. takes around 1-2 mins to lemmatize entire corpus\n","df['lemmatized_nostop_words'] = df['nostop_words'].apply(lemmatizing_tweets)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N4T2u08cYxCB","executionInfo":{"status":"ok","timestamp":1651472251835,"user_tz":240,"elapsed":120013,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"4336f13d-874a-4e1b-f2d0-1b8cd2c2fa1f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \n"]}]},{"cell_type":"markdown","source":["# 3. Model having BERT Word Embedding with StopWords"],"metadata":{"id":"R564fihbLHcG"}},{"cell_type":"code","source":["num_classes = 3 # 'neutral':0, 'negative':1, 'positive':2"],"metadata":{"id":"h_OnRl4OOQxg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# take a peek at the data\n","df[['clean_text', 'airline_sentiment']].head().values"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0w4jsU0mlwUT","executionInfo":{"status":"ok","timestamp":1651472251837,"user_tz":240,"elapsed":35,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"9c74591b-741f-4081-a2b8-a44039dc0635"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[' what said ', 0],\n","       [' plus you ve added commercials to the experience tacky ', 2],\n","       [' i didn t today must mean i need to take another trip ', 0],\n","       [' it s really aggressive to blast obnoxious entertainment in your guests faces amp they have little recourse',\n","        1],\n","       [' and it s a really big bad thing about it', 1]], dtype=object)"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["clean_text = df['clean_text'].values.tolist()\n","airline_sentiment = df['airline_sentiment'].values.tolist()"],"metadata":{"id":"tnC-w_UumFZ0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_x, test_x, train_y, test_y = train_test_split(clean_text,airline_sentiment, test_size = 0.25, random_state = 42)\n","len(train_x),len(test_x),len(train_y),len(test_y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"01aPQNN4mZ-E","executionInfo":{"status":"ok","timestamp":1651472251840,"user_tz":240,"elapsed":27,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"bb0610eb-24e6-468d-a6a3-8653bcb292af"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10980, 3660, 10980, 3660)"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["# Load pre-trained model tokenizer (vocabulary)\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',do_lower_case = True)\n","bert_model = TFBertModel.from_pretrained('bert-base-uncased')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":252,"referenced_widgets":["20399eceaaf1413ebad57b75fbe61716","f68c7090f95b48f082b229c55fd02564","2fc706c69e9646c2958c51abd13f0bec","c5ea4846e71f4be38218e36f625f1f50","71d573db06ec4a5fa39a6cdd9a2c889a","1aa52221f20c4e7e885cfb886a8654ec","97f32e1aae624951831508301f52a851","ece4ca554e424be1a4293d4fbc18169c","88f8afb7da7747bd82630de3b2a6e60e","1828174fc1f64ed8ac887581eee2e4a9","0231d516393b4e52bb950e48c255d54a","ed91e64f719f43c0bc222a755b63b90f","b39c5fae42d749efada08fb1c4134853","bb260b9338d44dd787f6c989fd222105","83feaa5a748f46ce94e0ef3fb3c60f91","11f3d61d1d89452a993c279bc93e9626","bc4444791bae4cebab4d33d4851643aa","1d6164949a0c4674b3c3f405223f0c6d","444f1d02a8604bd2bcc6b28971d6be45","ffd5e8b23a454c8e8a360a329057b917","ed072667fa004443ac180e1d74bbe2ec","193fa27152de44c8b4e7a3af4255d896","7d7afcf5538341aea71918ac18a047b9","8fc48420d2544ca59a88d566e61a21eb","342070d5bab849d69227362e945c8995","55f218dbf66d4be7a9fcbad8cc9a27ae","0ea80dbd12d54315a9ef6db6713ff12a","f9de4ba695664882abfc913277e56c9b","250ca7c9295f4ab38fd0f1e75a2779f0","5b0097b700ea497498f18705680520ae","254aba906b2242608698114322ff62c6","dee35c6ed8c3450096f4a94254e0c8bd","f1c9d73b42014772a08fc695af6f62bb","1545e3baccad4a918234dfbcecc08a80","c89ef94166e54a69ba5fff45fc4a4c27","a1806e3d23e5405bb31a2274db2c58bb","0e42e3889e0f4de5ae24d53502ef4536","075f493254ed4d038e99180fdb8aab1e","adf59bfd86c045cbbea7008a05d58f8b","c951a50a91804c8c906d3ab9d93aba77","1d1c0a0a617f4508be9419a9bc0f8d3d","e2f33fcb2a2c4519b057392a4db443cb","3e5ca558818244dba7a23d18f4dd532d","7c31a839fbfd4ed7999d1545ca5ea599"]},"id":"sW8HQavmsjff","executionInfo":{"status":"ok","timestamp":1651472272313,"user_tz":240,"elapsed":20491,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"a6a2385e-a6e9-4bc3-f7ed-8913d1b00d3e"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20399eceaaf1413ebad57b75fbe61716"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed91e64f719f43c0bc222a755b63b90f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d7afcf5538341aea71918ac18a047b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/511M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1545e3baccad4a918234dfbcecc08a80"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]}]},{"cell_type":"code","source":["def bert_tokenizer(data):\n","  encoding = tokenizer.batch_encode_plus(data,padding=True)\n","  return tf.constant(encoding['input_ids'])"],"metadata":{"id":"_szvOnQreopa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_tokenized = bert_tokenizer(train_x)\n","test_tokenized = bert_tokenizer(test_x)"],"metadata":{"id":"3x5-Iu2BQAnW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size=32"],"metadata":{"id":"Iv-ukuqrvwDK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# convert class vectors to binary class matrices- one hot encoding\n","from tensorflow import keras\n","\n","y_train = keras.utils.to_categorical(train_y, num_classes)\n","y_test = keras.utils.to_categorical(test_y, num_classes)"],"metadata":{"id":"viq5vKc1Q6YL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# building tensorflow data input pipeline\n","\n","# extract, transform, load\n","train_dataset =(\n","    tf.data.Dataset\n","    .from_tensor_slices((train_tokenized, y_train)) # extracting the data\n","    .shuffle(128) # randomly shuffle the entries with buffer size of 128\n","    .batch(batch_size) # required to run training model in multiple GPU\n",")\n","\n","test_dataset = (\n","    tf.data.Dataset\n","    .from_tensor_slices((test_tokenized, y_test))\n","    .shuffle(128)\n","    .batch(batch_size)\n",")"],"metadata":{"id":"ibfxdq71OePX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def build_bertmodel():\n","    word_inputs = tf.keras.Input(shape=(None,),dtype=tf.int32)\n","    last_hidden_states = bert_model(word_inputs)[0]\n","    x = tf.keras.layers.SpatialDropout1D(0.2)(last_hidden_states)\n","    x = tf.keras.layers.Bidirectional(LSTM(64, dropout=0.2))(x)\n","    x = tf.keras.layers.Dense(128, activation = 'relu')(x)\n","    x = tf.keras.layers.Dropout(0.5)(x)\n","    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n","    model = tf.keras.Model(word_inputs, outputs)\n","    return model"],"metadata":{"id":"2F5gYDluMdbG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["base_bertmodel = build_bertmodel()\n","base_bertmodel.compile(loss='categorical_crossentropy',optimizer=\"adam\",metrics=['accuracy'])\n","\n","base_bertmodel.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jK0bM5yGyWrR","executionInfo":{"status":"ok","timestamp":1651472313295,"user_tz":240,"elapsed":3022,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"cdda76ce-5f75-4e07-8405-193f8ec899c2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, None)]            0         \n","                                                                 \n"," tf_bert_model (TFBertModel)  TFBaseModelOutputWithPoo  109482240\n","                             lingAndCrossAttentions(l            \n","                             ast_hidden_state=(None,             \n","                             None, 768),                         \n","                              pooler_output=(None, 76            \n","                             8),                                 \n","                              past_key_values=None, h            \n","                             idden_states=None, atten            \n","                             tions=None, cross_attent            \n","                             ions=None)                          \n","                                                                 \n"," spatial_dropout1d_1 (Spatia  (None, None, 768)        0         \n"," lDropout1D)                                                     \n","                                                                 \n"," bidirectional (Bidirectiona  (None, 128)              426496    \n"," l)                                                              \n","                                                                 \n"," dense (Dense)               (None, 128)               16512     \n","                                                                 \n"," dropout_37 (Dropout)        (None, 128)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 3)                 387       \n","                                                                 \n","=================================================================\n","Total params: 109,925,635\n","Trainable params: 109,925,635\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["\n","callbacks = [ ReduceLROnPlateau(monitor='val_loss', patience=5, cooldown=0),\n","              EarlyStopping(monitor='val_acc', min_delta=1e-5, patience=5)]"],"metadata":{"id":"pKgY7ekLS_hE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history = base_bertmodel.fit(\n","    train_dataset,\n","    batch_size=128,\n","    epochs=4,\n","    validation_data=test_dataset,\n","    verbose=1,\n","    callbacks = callbacks)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d3ulqzj9TBgr","executionInfo":{"status":"ok","timestamp":1651472670711,"user_tz":240,"elapsed":350915,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"28ee548f-f9df-43d2-9016-5f71b2a63cd6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/4\n","WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","344/344 [==============================] - ETA: 0s - loss: 0.9543 - accuracy: 0.6111WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n","344/344 [==============================] - 110s 246ms/step - loss: 0.9543 - accuracy: 0.6111 - val_loss: 0.9089 - val_accuracy: 0.6393 - lr: 0.0010\n","Epoch 2/4\n","344/344 [==============================] - ETA: 0s - loss: 0.9320 - accuracy: 0.6228WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n","344/344 [==============================] - 80s 233ms/step - loss: 0.9320 - accuracy: 0.6228 - val_loss: 0.9048 - val_accuracy: 0.6393 - lr: 0.0010\n","Epoch 3/4\n","344/344 [==============================] - ETA: 0s - loss: 0.9279 - accuracy: 0.6228WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n","344/344 [==============================] - 80s 233ms/step - loss: 0.9279 - accuracy: 0.6228 - val_loss: 0.9026 - val_accuracy: 0.6393 - lr: 0.0010\n","Epoch 4/4\n","344/344 [==============================] - ETA: 0s - loss: 0.9270 - accuracy: 0.6228WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n","344/344 [==============================] - 80s 233ms/step - loss: 0.9270 - accuracy: 0.6228 - val_loss: 0.9032 - val_accuracy: 0.6393 - lr: 0.0010\n"]}]},{"cell_type":"markdown","source":["# 4. XLNet Word Embedding with StopWords"],"metadata":{"id":"ix5pQojawvO0"}},{"cell_type":"code","source":["from numpy.core.fromnumeric import size\n","\n","xlnet_tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n","xlnet_model = TFXLNetModel.from_pretrained('xlnet-base-cased')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":220,"referenced_widgets":["a5b6fce38d174238a888ee73d7b331ed","013ec07469ee460aa00ef56e8e1a6ab0","bc0e6e5eb7104052b473d69f6fcb6f69","b5ab49a295824308be49fda6af162701","2ad92085588a4cd6ac00d1d80b33dede","78ead454defd4994aa34c264c54107bf","70324e65b1ea451cb9acbe619ae845a7","d2bc5e4f8d5d4366b011a443bc5d2dcd","977c1cb3e5b84e96963a0c0bd4231cf9","89840a3a4e8840f59289d0ea2fd7ce02","176896f12d7a430090b3d39578c70a12","845b8f9f727643f9b899db652435a6b9","90e9707a93494a3abde9a32345e1a282","de1c0e60a7af475c833f8e5ce89243cb","88f8608aa607498ba289b2be734bb01e","3b59db5b66e84842821ba46025afd9aa","7dd3491a371c4e2a856f05558677118d","ad77f1dffc164a2491900b04cf63c475","cbfda8055c524aec97a3572777aacf24","ace4e8e516ca42e880e421308c666a4e","568b19fefb0146bcb4807d5903343eba","b84d7a900d3741b396cb12e34682b395","43af434d7798437b9e830f2688fa4c99","081c2a88ef8046da8cf6abafb394bc7d","0872307fc9b74e29aef7afab0a979b6a","eb15f49c18fc4250a4815f4f59725256","c1b1515f250843798179c34bd9c92b10","7041b857816e48c392f9e622da835c7b","5efc441a47ec4ff19d532d9a65f57ece","212f8373ff7248ff921adb6a037e2c7f","65e5cfe6b0c04764b12f7da124f12f92","8178ac4036c0479587f2cf5b67ac7c65","ca6cd50eb6f648878de592137596bb5d"]},"id":"ZUSGoWKIWTM1","executionInfo":{"status":"ok","timestamp":1651460585285,"user_tz":240,"elapsed":41421,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"3e3091a9-3c02-4ffa-dc36-18374b796ef3"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/779k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5b6fce38d174238a888ee73d7b331ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/760 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"845b8f9f727643f9b899db652435a6b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/539M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43af434d7798437b9e830f2688fa4c99"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n","- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"]}]},{"cell_type":"code","source":["max_len = 120"],"metadata":{"id":"071LzPm6Y-fl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def xlnet_encode(text):\n","  train_tokenized = xlnet_tokenizer.batch_encode_plus(text,max_length= max_len, padding='max_length',return_tensors=\"pt\")\n","  return tf.constant(train_tokenized['input_ids'])"],"metadata":{"id":"6uqWFBfOzg-w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_encoded = xlnet_encode(train_x)\n","test_encoded = xlnet_encode(test_x)"],"metadata":{"id":"XQNPjRpDYTO5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_train = keras.utils.to_categorical(train_y, num_classes)\n","y_test = keras.utils.to_categorical(test_y, num_classes)"],"metadata":{"id":"tQUuuf-4RdCZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size=32"],"metadata":{"id":"JCgbvEobgrpn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_xlnet_dataset =(\n","    tf.data.Dataset\n","    .from_tensor_slices((train_encoded, y_train))\n","    .shuffle(128)\n","    .batch(batch_size)\n",")\n","\n","test_xlnet_dataset = (\n","    tf.data.Dataset\n","    .from_tensor_slices((test_encoded, y_test))\n","    .shuffle(128)\n","    .batch(batch_size)\n",")"],"metadata":{"id":"dnHGKuWSgeN5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def build_xlnetmodel():\n","  word_inputs = tf.keras.Input(shape=(max_len,), dtype='int32')\n","\n","  # Call XLNet model\n","  xlnet_encodings = xlnet_model(word_inputs)[0]\n","  doc_encoding = tf.keras.layers.SpatialDropout1D(0.2)(xlnet_encodings)\n","  x = tf.keras.layers.Bidirectional(LSTM(25, dropout=0.2, recurrent_dropout=0.2))(doc_encoding)\n","\n","  # Final output \n","  outputs = tf.keras.layers.Dense(num_classes, activation='softmax', name='outputs')(x)\n","\n","  # Compile model\n","  model = tf.keras.Model(inputs=[word_inputs], outputs=[outputs])\n","  model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n","  return model"],"metadata":{"id":"UPPBTsHxZ805"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["base_xlmodel = build_xlnetmodel()\n","base_xlmodel.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o1LF6K46gBlU","executionInfo":{"status":"ok","timestamp":1651460591932,"user_tz":240,"elapsed":3914,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"d1ea8bf5-3cf4-4d9f-ef3b-20940c4e06a3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Model: \"model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 120)]             0         \n","                                                                 \n"," tfxl_net_model (TFXLNetMode  TFXLNetModelOutput(last_  116718336\n"," l)                          hidden_state=(None, 120,            \n","                              768),                              \n","                              mems=((120, None, 768),            \n","                              (120, None, 768),                  \n","                              (120, None, 768),                  \n","                              (120, None, 768),                  \n","                              (120, None, 768),                  \n","                              (120, None, 768),                  \n","                              (120, None, 768),                  \n","                              (120, None, 768),                  \n","                              (120, None, 768),                  \n","                              (120, None, 768),                  \n","                              (120, None, 768),                  \n","                              (120, None, 768)),                 \n","                              hidden_states=None, att            \n","                             entions=None)                       \n","                                                                 \n"," spatial_dropout1d_1 (Spatia  (None, 120, 768)         0         \n"," lDropout1D)                                                     \n","                                                                 \n"," bidirectional_1 (Bidirectio  (None, 50)               158800    \n"," nal)                                                            \n","                                                                 \n"," outputs (Dense)             (None, 3)                 153       \n","                                                                 \n","=================================================================\n","Total params: 116,877,289\n","Trainable params: 116,877,289\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["def warmup(epoch, lr):\n","    \"\"\"Used for increasing the learning rate slowly, this tends to achieve better convergence.\n","    However, as we are finetuning for few epoch it's not crucial.\n","    \"\"\"\n","    return max(lr +1e-6, 2e-5)\n"],"metadata":{"id":"vKiARBHYg6S1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["callbacks = [\n","    tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=4, min_delta=0.02, restore_best_weights=True),\n","    tf.keras.callbacks.LearningRateScheduler(warmup, verbose=0),\n","    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=1e-6, patience=2, verbose=0, mode='auto', min_delta=0.001, cooldown=0, min_lr=1e-6)\n","]"],"metadata":{"id":"fmEB7ruwg0m4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history = base_xlmodel.fit(\n","    train_xlnet_dataset,\n","    batch_size=batch_size,\n","    epochs=1,\n","    validation_data=test_xlnet_dataset,\n","    verbose=1,\n","    callbacks = callbacks)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FETdB385iiqT","executionInfo":{"status":"ok","timestamp":1651461246299,"user_tz":240,"elapsed":68680,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"d815ce85-d9e7-42ab-b6bb-a26658a24f17"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model/transformer/mask_emb:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model/transformer/mask_emb:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","344/344 [==============================] - 654s 2s/step - loss: 0.9359 - accuracy: 0.6175 - val_loss: 0.9027 - val_accuracy: 0.6393 - lr: 0.0010\n"]}]},{"cell_type":"markdown","source":["# 5. Model having BERT Word Embedding without StopWords"],"metadata":{"id":"EqUws7tAyCTY"}},{"cell_type":"code","source":["# take a peek at the data\n","df[['nostop_words', 'airline_sentiment']].head().values"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cnQTxuQkyKzE","executionInfo":{"status":"ok","timestamp":1651461246300,"user_tz":240,"elapsed":11,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"a4ab2c00-ca83-4f63-e406-49989c78bd3d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([['  said ', 0],\n","       [' plus   added commercials   experience tacky ', 2],\n","       ['    today must mean  need  take another trip ', 0],\n","       ['   really aggressive  blast obnoxious entertainment   guests faces amp   little recourse',\n","        1],\n","       ['     really big bad thing  ', 1]], dtype=object)"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":["nostop_words = df['nostop_words'].values.tolist()\n","airline_sentiment = df['airline_sentiment'].values.tolist()"],"metadata":{"id":"-OZsTIewyPla"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_x, test_x, train_y, test_y = train_test_split(nostop_words,airline_sentiment, test_size = 0.25, random_state = 42)\n","len(train_x),len(test_x),len(train_y),len(test_y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Ap3YciPyfzW","executionInfo":{"status":"ok","timestamp":1651461246301,"user_tz":240,"elapsed":5,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"f10f6166-95ce-44fc-a7c8-d0b937d163e5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10980, 3660, 10980, 3660)"]},"metadata":{},"execution_count":47}]},{"cell_type":"code","source":["train_tokenized_nostop = bert_tokenizer(train_x)\n","test_tokenized_nostop = bert_tokenizer(test_x)"],"metadata":{"id":"fwi76xk1ypsL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_train = keras.utils.to_categorical(train_y, num_classes)\n","y_test = keras.utils.to_categorical(test_y, num_classes)"],"metadata":{"id":"nk991m3rw2JC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size=32"],"metadata":{"id":"iPzUgk5_yxzt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# building tensorflow data input pipeline\n","\n","# extract, transform, load\n","train_dataset_nostop =(\n","    tf.data.Dataset\n","    .from_tensor_slices((train_tokenized_nostop, y_train)) # extracting the data\n","    .shuffle(128) # randomly shuffle the entries with buffer size of 128\n","    .batch(batch_size) # required to run training model in multiple GPU\n",")\n","\n","test_dataset_nostop = (\n","    tf.data.Dataset\n","    .from_tensor_slices((test_tokenized_nostop, y_test))\n","    .shuffle(128)\n","    .batch(batch_size)\n",")"],"metadata":{"id":"BKTsSS8my1B6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bertmodel_nostop = build_bertmodel()\n","\n","bertmodel_nostop.compile(loss='categorical_crossentropy',optimizer=\"adam\",metrics=['accuracy'])\n","\n","bertmodel_nostop.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uu9kt4V5y-vR","executionInfo":{"status":"ok","timestamp":1651461312409,"user_tz":240,"elapsed":2885,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"58634a40-6c33-4fd9-ff1a-60a2af018467"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Model: \"model_4\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_5 (InputLayer)        [(None, None)]            0         \n","                                                                 \n"," tf_bert_model (TFBertModel)  TFBaseModelOutputWithPoo  109482240\n","                             lingAndCrossAttentions(l            \n","                             ast_hidden_state=(None,             \n","                             None, 768),                         \n","                              pooler_output=(None, 76            \n","                             8),                                 \n","                              past_key_values=None, h            \n","                             idden_states=None, atten            \n","                             tions=None, cross_attent            \n","                             ions=None)                          \n","                                                                 \n"," spatial_dropout1d_4 (Spatia  (None, None, 768)        0         \n"," lDropout1D)                                                     \n","                                                                 \n"," bidirectional_4 (Bidirectio  (None, 50)               158800    \n"," nal)                                                            \n","                                                                 \n"," dense_3 (Dense)             (None, 3)                 153       \n","                                                                 \n","=================================================================\n","Total params: 109,641,193\n","Trainable params: 109,641,193\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["bertmodel_nostop.fit(\n","    train_dataset_nostop,\n","    batch_size=batch_size,\n","    epochs=1,\n","    validation_data=test_dataset_nostop,\n","    verbose=1,\n","    callbacks = callbacks)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4uJkJBIqzINc","executionInfo":{"status":"ok","timestamp":1651461542002,"user_tz":240,"elapsed":48660,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"96ce06b0-ad2e-4b9f-c0a1-cca37a6b7135"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","344/344 [==============================] - 226s 599ms/step - loss: 0.9263 - accuracy: 0.6209 - val_loss: 0.9025 - val_accuracy: 0.6393 - lr: 0.0010\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f00968d6350>"]},"metadata":{},"execution_count":57}]},{"cell_type":"markdown","source":["# 6. Model having XLNet Word Embedding without StopWords"],"metadata":{"id":"eRHwj1dVzVlb"}},{"cell_type":"code","source":["train_encode_xlnetnostop = xlnet_encode(train_x)\n","test_encode_xlnetnostop = xlnet_encode(test_x)"],"metadata":{"id":"S4WymexXzZUN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size=32"],"metadata":{"id":"S8mihLDQ0aIX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset_xlent_nostop =(\n","    tf.data.Dataset\n","    .from_tensor_slices((train_encode_xlnetnostop, y_train))\n","    .shuffle(128)\n","    .batch(batch_size)\n",")\n","\n","test_dataset_xlent_nostop = (\n","    tf.data.Dataset\n","    .from_tensor_slices((test_encode_xlnetnostop, y_test))\n","    .shuffle(128)\n","    .batch(batch_size)\n",")"],"metadata":{"id":"rmf_qVmY0aIY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["xlnetModel_nostop = build_xlnetmodel()\n","xlnetModel_nostop.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eBiNdvty2TxY","executionInfo":{"status":"ok","timestamp":1651461628454,"user_tz":240,"elapsed":1852,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"053850cb-834d-429d-92fa-786d48a9e61a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Model: \"model_5\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_6 (InputLayer)        [(None, 120)]             0         \n","                                                                 \n"," tfxl_net_model (TFXLNetMode  TFXLNetModelOutput(last_  116718336\n"," l)                          hidden_state=(None, 120,            \n","                              768),                              \n","                              mems=((120, None, 768),            \n","                              (120, None, 768),                  \n","                              (120, None, 768),                  \n","                              (120, None, 768),                  \n","                              (120, None, 768),                  \n","                              (120, None, 768),                  \n","                              (120, None, 768),                  \n","                              (120, None, 768),                  \n","                              (120, None, 768),                  \n","                              (120, None, 768),                  \n","                              (120, None, 768),                  \n","                              (120, None, 768)),                 \n","                              hidden_states=None, att            \n","                             entions=None)                       \n","                                                                 \n"," spatial_dropout1d_5 (Spatia  (None, 120, 768)         0         \n"," lDropout1D)                                                     \n","                                                                 \n"," bidirectional_5 (Bidirectio  (None, 50)               158800    \n"," nal)                                                            \n","                                                                 \n"," outputs (Dense)             (None, 3)                 153       \n","                                                                 \n","=================================================================\n","Total params: 116,877,289\n","Trainable params: 116,877,289\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["xlnetModel_nostop.fit(\n","    train_dataset_xlent_nostop,\n","    batch_size=batch_size,\n","    epochs=1,\n","    validation_data=test_dataset_xlent_nostop,\n","    verbose=1,\n","    callbacks = callbacks)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tDz8j8QH2ZdL","executionInfo":{"status":"ok","timestamp":1651462290174,"user_tz":240,"elapsed":64256,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"3c745f2f-64f3-406a-e801-8ddc5d3c9f05"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model/transformer/mask_emb:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model/transformer/mask_emb:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","344/344 [==============================] - 657s 2s/step - loss: 0.9290 - accuracy: 0.6192 - val_loss: 0.9027 - val_accuracy: 0.6393 - lr: 0.0010\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f02f9e1b9d0>"]},"metadata":{},"execution_count":62}]},{"cell_type":"markdown","source":["Summarizing Performace of the Models so far.\n","```\n","\n","+-----------------------------------------------------+----------+\n","|                 Parameter Settings                  | Accuracy |\n","+-----------------------------------------------------+----------+\n","| BERT Word Embedding + StopWords                     | 64%      |\n","| XLNet Word Embedding + StopWords                    | 64%      |\n","| BERT Word Embedding + No StopWords                  | 64%      |\n","| XLNet Word Embedding + No StopWords                 | 64%      |\n","+-----------------------------------------------------+----------+\n","```\n","From the above Stats, all the models have similar performace hence we can choose any of the models for further training. Using `XLNet Model with Stop Words` to train the model with lemmatization.\n","\n","\n"],"metadata":{"id":"1V8Xx7KR3Jzs"}},{"cell_type":"markdown","source":["# 7. Model having XLNet Word Embedding with Lemmatization + with Stop Words"],"metadata":{"id":"bf-imQqD2zOS"}},{"cell_type":"code","source":["# take a peek at the data\n","df[['lemmatized_text', 'airline_sentiment']].head().values"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dyM_4c0k5qwN","executionInfo":{"status":"ok","timestamp":1651462306198,"user_tz":240,"elapsed":293,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"0ce7dc19-04c3-4c4c-d673-c2089ce239f7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([['  what say', 0],\n","       ['  plus -PRON- ve add commercial to the experience tacky', 2],\n","       ['  i didn t today must mean i need to take another trip', 0],\n","       ['  -PRON- s really aggressive to blast obnoxious entertainment in -PRON- guest face amp -PRON- have little recourse',\n","        1],\n","       ['  and -PRON- s a really big bad thing about -PRON-', 1]],\n","      dtype=object)"]},"metadata":{},"execution_count":63}]},{"cell_type":"code","source":["lemmatized_text = df['lemmatized_text'].values.tolist()\n","airline_sentiment = df['airline_sentiment'].values.tolist()"],"metadata":{"id":"00_JKaTJ58ap"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_x, test_x, train_y, test_y = train_test_split(clean_text,airline_sentiment, test_size = 0.25, random_state = 42)\n","len(train_x),len(test_x),len(train_y),len(test_y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651462309827,"user_tz":240,"elapsed":4,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"a57dd32d-016c-435b-e3ec-a0e974d52bb4","id":"G4Rll8gq58ap"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10980, 3660, 10980, 3660)"]},"metadata":{},"execution_count":65}]},{"cell_type":"code","source":["train_xlnet_lemmatized = xlnet_encode(train_x)\n","test_xlnet_lemmatized = xlnet_encode(test_x)"],"metadata":{"id":"aosAM1To6FoP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size=32"],"metadata":{"id":"9HaNYc-H6FoP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_xlnet_lemmatized_dataset =(\n","    tf.data.Dataset\n","    .from_tensor_slices((train_xlnet_lemmatized, y_train))\n","    .shuffle(128)\n","    .batch(batch_size)\n",")\n","\n","test_xlnet_lemmatized_dataset = (\n","    tf.data.Dataset\n","    .from_tensor_slices((test_xlnet_lemmatized, y_test))\n","    .shuffle(128)\n","    .batch(batch_size)\n",")"],"metadata":{"id":"oRaI9rI56FoP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lemmatized_xlmodel = build_xlnetmodel()\n","lemmatized_xlmodel.summary()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651462332618,"user_tz":240,"elapsed":2216,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"04a66fb3-d9b0-446f-e254-823f91855f77","id":"5Z2-k9oX6FoP"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Model: \"model_6\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_7 (InputLayer)        [(None, 120)]             0         \n","                                                                 \n"," tfxl_net_model (TFXLNetMode  TFXLNetModelOutput(last_  116718336\n"," l)                          hidden_state=(None, 120,            \n","                              768),                              \n","                              mems=((120, None, 768),            \n","                              (120, None, 768),                  \n","                              (120, None, 768),                  \n","                              (120, None, 768),                  \n","                              (120, None, 768),                  \n","                              (120, None, 768),                  \n","                              (120, None, 768),                  \n","                              (120, None, 768),                  \n","                              (120, None, 768),                  \n","                              (120, None, 768),                  \n","                              (120, None, 768),                  \n","                              (120, None, 768)),                 \n","                              hidden_states=None, att            \n","                             entions=None)                       \n","                                                                 \n"," spatial_dropout1d_6 (Spatia  (None, 120, 768)         0         \n"," lDropout1D)                                                     \n","                                                                 \n"," bidirectional_6 (Bidirectio  (None, 50)               158800    \n"," nal)                                                            \n","                                                                 \n"," outputs (Dense)             (None, 3)                 153       \n","                                                                 \n","=================================================================\n","Total params: 116,877,289\n","Trainable params: 116,877,289\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["callbacks2 = [\n","    tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=4, min_delta=0.02, restore_best_weights=True),\n","    tf.keras.callbacks.LearningRateScheduler(warmup, verbose=0),\n","    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=1e-6, patience=2, verbose=0, mode='auto', min_delta=0.001, cooldown=0, min_lr=1e-6)\n","]"],"metadata":{"id":"pUXXjS3B6xBN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lemmatized_xlmodel.fit(\n","    train_xlnet_lemmatized_dataset,\n","    batch_size=batch_size,\n","    epochs=1,\n","    validation_data=test_xlnet_lemmatized_dataset,\n","    verbose=1,\n","    callbacks = callbacks2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651462996094,"user_tz":240,"elapsed":657627,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"eb7697ae-f1dc-404f-c82e-47210b09ed66","id":"CZSFuFX76FoP"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model/transformer/mask_emb:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model/transformer/mask_emb:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","344/344 [==============================] - 657s 2s/step - loss: 0.9265 - accuracy: 0.6214 - val_loss: 0.9022 - val_accuracy: 0.6393 - lr: 0.0010\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f02f8e5c550>"]},"metadata":{},"execution_count":72}]},{"cell_type":"markdown","source":["Conclusion: Comparing accuracies of all the models\n","```\n","\n","+--------------------------------------------------+----------+\n","|                parameter settings                | Accuracy |\n","+--------------------------------------------------+----------+\n","| BERT Word Embedding + StopWords                  | 64%      |\n","| XLNet Word Embedding + StopWords                 | 64%    |\n","| BERT Word Embedding + No StopWords               | 64%      |\n","| XLNet Word Embedding + No StopWords              | 64%      |\n","| XLNet Word Embedding + StopWords + Lemmatization | 64%      |\n","+--------------------------------------------------+----------+\n","```\n","all the models are having similar performance with accuracy of 64%."],"metadata":{"id":"4EhGHgba8VJ0"}},{"cell_type":"markdown","source":["#8. HyperParameter Tuning - batch size and number of epochs\n","\n","---\n","\n"],"metadata":{"id":"VYiGNwjA8Ipp"}},{"cell_type":"code","source":["word_inputs = tf.keras.Input(shape=(None,), dtype='int32')\n","# Call XLNet model\n","xlnet_encodings = xlnet_model(word_inputs)[0]\n","doc_encoding = tf.keras.layers.SpatialDropout1D(0.5)(xlnet_encodings)\n","x = tf.keras.layers.Bidirectional(LSTM(25, dropout=0.5, recurrent_dropout=0.5))(doc_encoding)\n","\n","# Final output \n","outputs = tf.keras.layers.Dense(num_classes, activation='softmax', name='outputs')(x)\n","\n","# Compile modela\n","model1 = tf.keras.Model(inputs=[word_inputs], outputs=[outputs])\n","model1.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"joRoBIPg9KPZ","executionInfo":{"status":"ok","timestamp":1651464656533,"user_tz":240,"elapsed":1958,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"81d6dc12-f273-47a3-d23a-2fd438686a96"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]}]},{"cell_type":"code","source":["model1.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i_mdtohz9vF6","executionInfo":{"status":"ok","timestamp":1651464667261,"user_tz":240,"elapsed":352,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"b8f23b91-33bc-40c7-ebb5-b83b34bf3a14"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_7\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_8 (InputLayer)        [(None, None)]            0         \n","                                                                 \n"," tfxl_net_model (TFXLNetMode  multiple                 116718336 \n"," l)                                                              \n","                                                                 \n"," spatial_dropout1d_7 (Spatia  (None, None, 768)        0         \n"," lDropout1D)                                                     \n","                                                                 \n"," bidirectional_7 (Bidirectio  (None, 50)               158800    \n"," nal)                                                            \n","                                                                 \n"," outputs (Dense)             (None, 3)                 153       \n","                                                                 \n","=================================================================\n","Total params: 116,877,289\n","Trainable params: 116,877,289\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["base_xlmodel.fit(\n","    train_xlnet_dataset,\n","    batch_size=64,\n","    epochs=1,\n","    validation_data=test_xlnet_dataset,\n","    verbose=1,\n","    callbacks = callbacks)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BbyL3OAq9tEJ","executionInfo":{"status":"ok","timestamp":1651465328739,"user_tz":240,"elapsed":45887,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"3bf132a0-65e5-465e-9818-b4c8fcb8ee6d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["344/344 [==============================] - 637s 2s/step - loss: 0.9211 - accuracy: 0.6228 - val_loss: 0.9019 - val_accuracy: 0.6393 - lr: 0.0010\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f0093d7b350>"]},"metadata":{},"execution_count":76}]},{"cell_type":"code","source":["base_xlmodel.fit(\n","    train_xlnet_dataset,\n","    batch_size=128,\n","    epochs=1,\n","    validation_data=test_xlnet_dataset,\n","    verbose=1,\n","    callbacks = callbacks)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fHHchThF-Z39","executionInfo":{"status":"ok","timestamp":1651465966561,"user_tz":240,"elapsed":345382,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"d096c8fa-e6c0-41ef-aa4c-1345423bd7cb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["344/344 [==============================] - 638s 2s/step - loss: 0.9211 - accuracy: 0.6228 - val_loss: 0.9022 - val_accuracy: 0.6393 - lr: 0.0010\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f0093d818d0>"]},"metadata":{},"execution_count":77}]},{"cell_type":"code","source":["base_xlmodel.fit(\n","    train_xlnet_dataset,\n","    batch_size=256,\n","    epochs=1,\n","    validation_data=test_xlnet_dataset,\n","    verbose=1,\n","    callbacks = callbacks)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pyoudhcO-dn6","executionInfo":{"status":"ok","timestamp":1651466601607,"user_tz":240,"elapsed":237762,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"ee35d1bf-65b2-45bd-df8a-92402b3acd00"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["344/344 [==============================] - 635s 2s/step - loss: 0.9211 - accuracy: 0.6228 - val_loss: 0.9024 - val_accuracy: 0.6393 - lr: 0.0010\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f0093d83190>"]},"metadata":{},"execution_count":78}]},{"cell_type":"markdown","source":["#9. Predictions"],"metadata":{"id":"LFW1IIxk7wvG"}},{"cell_type":"code","source":["# importing data set\n","corpus_root = '/content/drive/Othercomputers/My Laptop/syr_ads_ist664/hw03/covid_data.json' # will have to replace this value with your data set file path\n","\n","# data set is a json file with multiple json object hence iterating over each json object to extract the news/blogs\n","json_list = []\n","with open(corpus_root,encoding='utf8') as file_handler:\n","    for json_obj in file_handler:\n","        data = json.loads(json_obj)\n","        json_list.append(data)"],"metadata":{"id":"1H5-3o1W_pIo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["covid_df = pd.DataFrame(json_list)"],"metadata":{"id":"WfPxC1S3C4jy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# viewing first 5 rows to undertand the dataset\n","covid_df.head(2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":332},"id":"EWo0mPJsC7kB","executionInfo":{"status":"ok","timestamp":1651466666431,"user_tz":240,"elapsed":466,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"efb7bad7-07df-408b-a8e5-3060bc1da2b8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["  organizations                                      uuid  \\\n","0            []  0ad32fb9226b172b960cba62027cd8be7d9dfa22   \n","1            []  8c3c1e13471a5e6ef7e115588ab27f308285cf2e   \n","\n","                                              thread     author  \\\n","0  {'social': {'gplus': {'shares': 0}, 'pinterest...  Udayavani   \n","1  {'social': {'gplus': {'shares': 0}, 'pinterest...              \n","\n","                                                 url  ord_in_thread  \\\n","0  https://m.dailyhunt.in/news/india/english/uday...              0   \n","1  http://cnnphilippines.com/videos/2020/1/28/Hea...              0   \n","\n","                                               title locations  \\\n","0  Karnataka: Helplines, isolation wards set up f...        []   \n","1  Health dept. monitoring 24 people for possible...        []   \n","\n","                                            entities highlightText language  \\\n","0  {'persons': [], 'locations': [{'name': 'karnat...                english   \n","1  {'persons': [], 'locations': [{'name': 'hubei'...                english   \n","\n","  persons                                               text external_links  \\\n","0      []  Bengaluru: Isolation wards in hospitals across...             []   \n","1      []  The government making sure that the new corona...             []   \n","\n","                       published                        crawled highlightTitle  \n","0  2020-01-31T11:46:00.000+02:00  2020-01-31T17:18:04.007+02:00                 \n","1  2020-01-28T02:00:00.000+02:00  2020-01-31T06:38:31.000+02:00                 "],"text/html":["\n","  <div id=\"df-11e14d99-f89b-46a4-ad15-1057760c1fd1\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>organizations</th>\n","      <th>uuid</th>\n","      <th>thread</th>\n","      <th>author</th>\n","      <th>url</th>\n","      <th>ord_in_thread</th>\n","      <th>title</th>\n","      <th>locations</th>\n","      <th>entities</th>\n","      <th>highlightText</th>\n","      <th>language</th>\n","      <th>persons</th>\n","      <th>text</th>\n","      <th>external_links</th>\n","      <th>published</th>\n","      <th>crawled</th>\n","      <th>highlightTitle</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[]</td>\n","      <td>0ad32fb9226b172b960cba62027cd8be7d9dfa22</td>\n","      <td>{'social': {'gplus': {'shares': 0}, 'pinterest...</td>\n","      <td>Udayavani</td>\n","      <td>https://m.dailyhunt.in/news/india/english/uday...</td>\n","      <td>0</td>\n","      <td>Karnataka: Helplines, isolation wards set up f...</td>\n","      <td>[]</td>\n","      <td>{'persons': [], 'locations': [{'name': 'karnat...</td>\n","      <td></td>\n","      <td>english</td>\n","      <td>[]</td>\n","      <td>Bengaluru: Isolation wards in hospitals across...</td>\n","      <td>[]</td>\n","      <td>2020-01-31T11:46:00.000+02:00</td>\n","      <td>2020-01-31T17:18:04.007+02:00</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>[]</td>\n","      <td>8c3c1e13471a5e6ef7e115588ab27f308285cf2e</td>\n","      <td>{'social': {'gplus': {'shares': 0}, 'pinterest...</td>\n","      <td></td>\n","      <td>http://cnnphilippines.com/videos/2020/1/28/Hea...</td>\n","      <td>0</td>\n","      <td>Health dept. monitoring 24 people for possible...</td>\n","      <td>[]</td>\n","      <td>{'persons': [], 'locations': [{'name': 'hubei'...</td>\n","      <td></td>\n","      <td>english</td>\n","      <td>[]</td>\n","      <td>The government making sure that the new corona...</td>\n","      <td>[]</td>\n","      <td>2020-01-28T02:00:00.000+02:00</td>\n","      <td>2020-01-31T06:38:31.000+02:00</td>\n","      <td></td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-11e14d99-f89b-46a4-ad15-1057760c1fd1')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-11e14d99-f89b-46a4-ad15-1057760c1fd1 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-11e14d99-f89b-46a4-ad15-1057760c1fd1');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":81}]},{"cell_type":"code","source":["def get_inputs(sent, tokenizer):\n","    inps = tokenizer.encode_plus(sent, padding='max_length', max_length=max_len) \n","    inp_tok = np.array([inps['input_ids']])\n","    return inp_tok"],"metadata":{"id":"zvv6ptyRD2Hn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["covid_df['text'] = covid_df['text'].apply(str.lower) # data pre-processing\n","tempdf = covid_df.iloc[:200]"],"metadata":{"id":"sc7aWhcsDILN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tempdf.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z0uqvNHLFagA","executionInfo":{"status":"ok","timestamp":1651466679692,"user_tz":240,"elapsed":453,"user":{"displayName":"Chaithra K.C","userId":"06590399226295405413"}},"outputId":"f00725e6-56c7-4a8c-b6ad-3e175aee8609"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(200, 17)"]},"metadata":{},"execution_count":84}]},{"cell_type":"code","source":["nltk.download('punkt')\n","# iterating over each news article to predict the sentiment\n","for index,row in tempdf.iterrows():\n","  sents = nltk.sent_tokenize(row['text'])\n","  num_pos_score = 0\n","  num_neg_score = 0\n","  num_neutral_score = 0\n","  for sent in sents:\n","    print(sent)\n","    try:\n","      encoding = get_inputs(sent,xlnet_tokenizer)  \n","      pred_arr = base_xlmodel.predict(encoding, verbose=False) # predicting the sentiment\n","      # picking the array index having highest probability\n","      argIndex = np.argmax(pred_arr[0],axis=-1) \n","    except:\n","      continue\n","    if argIndex == 2:\n","        num_pos_score = num_pos_score + 1\n","    elif argIndex == 1:\n","        num_neg_score = num_neg_score + 1\n","    elif argIndex == 0:\n","        num_neutral_score = num_neutral_score + 1       \n","  tempdf.loc[index, 'the number of positive sentences'] = num_pos_score\n","  tempdf.loc[index, 'the number of negative sentences'] = num_neg_score\n","  tempdf.loc[index, 'the number of neutral sentences'] = num_neutral_score"],"metadata":{"id":"yxv13QHJDXMi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# writing the output to csv\n","tempdf.to_csv('/content/drive/Othercomputers/My Laptop/syr_ads_ist664/hw03/chaithra_kopparam_cheluvaiah_out.csv')"],"metadata":{"id":"wa3mxcs2Uhg_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["External Sources Used:\n","\n","https://www.youtube.com/watch?v=VFEOskzhhbc \n","\n","https://github.com/codebasics/deep-learning-keras-tf-tutorial/blob/master/44_tf_data_pipeline/tf_data_pipeline.ipynb \n","\n","https://www.kaggle.com/code/rihab147/xlnet-tunisian-sentiment-analysis/notebook \n","\n","https://www.kaggle.com/code/dhruv1234/huggingface-tfbertmodel/notebook \n","\n","https://www.kaggle.com/code/christofhenkel/bert-embeddings-lstm/notebook "],"metadata":{"id":"dBOsT0BctYRB"}}]}